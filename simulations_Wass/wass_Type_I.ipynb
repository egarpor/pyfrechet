{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergencia Tipo X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys, os; sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from pyfrechet.metric_spaces import MetricData, LogCholesky, spd_to_log_chol, log_chol_to_spd\n",
    "from pyfrechet.regression.bagged_regressor import BaggedRegressor\n",
    "from pyfrechet.regression.trees import Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyfrechet.metric_spaces import MetricData, LogEuclidean, CustomAffineInvariant, CustomLogEuclidean, AffineInvariant, LogCholesky, log_chol_to_spd, spd_to_log_chol\n",
    "\n",
    "from scipy.special import digamma\n",
    "from scipy.stats import wishart\n",
    "\n",
    "from typing import Union\n",
    "import random\n",
    "from pyfrechet.metric_spaces import wasserstein_1d as ws\n",
    "from pyfrechet.metric_spaces import MetricData, Wasserstein1D\n",
    "from scipy import stats \n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID = np.linspace(0.01, 0.99, 100)\n",
    "STD_NORMAL_Q = stats.norm.ppf(GRID)\n",
    "\n",
    "\n",
    "def sample_linear_transport(x, sig=1, gam=0.5):\n",
    "    gam = np.random.gamma(0.5, 0.5)\n",
    "    sig = np.random.exponential(0.5)\n",
    "    Q0 = gam - np.log(1 + x) + (sig + x**2) * STD_NORMAL_Q\n",
    "    return Q0 \n",
    "    \n",
    "def gen_data(N):\n",
    "    # We know the values of Q in a grid, and we interpolate to estimate the values of Q in the new grid\n",
    "    x = np.random.uniform(0,1, N)\n",
    "    y = np.array([ sample_linear_transport(x[i]) for i in range(N)])\n",
    "    \n",
    "    return {'x': x, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Obtain coverage results dataframe from the results files\n",
    "def coverage_results() -> pd.DataFrame:\n",
    "    \"\"\"Create a dataframe with the data to be analyzed from the results files.\"\"\"\n",
    "\n",
    "    coverage_df=pd.DataFrame(columns=['sample_index', 'y_train_data', 'train_predictions', 'OOB_quantile', 'forest'])\n",
    "    for file in os.listdir(os.path.join(os.getcwd(), 'wass_results')):\n",
    "        if file.endswith('.npy'):\n",
    "            infile=open(os.path.join(os.getcwd(), 'wass_results/' + file), 'rb')\n",
    "            result=np.load(infile, allow_pickle=True).item()\n",
    "            infile.close()\n",
    "            coverage_df=pd.concat([coverage_df, \n",
    "                                    pd.DataFrame({  'sample_index': int(file.split('_')[1][4:]),\n",
    "                                                    'y_train_data': [result['y_train_data']],\n",
    "                                                    'train_predictions': [result['train_predictions']],\n",
    "                                                    'forest': [result['forest']],\n",
    "                                                }, index=pd.RangeIndex(0,1))],\n",
    "                                    ignore_index=True)\n",
    "        \n",
    "    coverage_df['sample_index']=coverage_df['sample_index'].astype('category')\n",
    "    return coverage_df\n",
    "\n",
    "coverage_df=coverage_results()\n",
    "#coverage_df_LC=coverage_results(dfs = dfs_names, dist = 'LC')\n",
    "#coverage_df_LE=coverage_results(dfs = dfs_names, dist = 'LE')\n",
    "#\n",
    "#coverage_df_combined = pd.concat([coverage_df, coverage_df_LC, coverage_df_LE], ignore_index=True)\n",
    "#print(coverage_df.info())\n",
    "#print(coverage_df_LC.info())\n",
    "#print(coverage_df_LE.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.974, 0.942, 0.894],\n",
       "       [0.978, 0.937, 0.883],\n",
       "       [0.973, 0.92 , 0.866],\n",
       "       [0.98 , 0.939, 0.888],\n",
       "       [0.975, 0.932, 0.886],\n",
       "       [0.971, 0.925, 0.87 ],\n",
       "       [0.972, 0.918, 0.857],\n",
       "       [0.974, 0.917, 0.86 ],\n",
       "       [0.981, 0.934, 0.884],\n",
       "       [0.976, 0.935, 0.879],\n",
       "       [0.963, 0.922, 0.861],\n",
       "       [0.974, 0.93 , 0.876],\n",
       "       [0.977, 0.924, 0.874],\n",
       "       [0.964, 0.919, 0.874],\n",
       "       [0.977, 0.931, 0.872],\n",
       "       [0.984, 0.926, 0.869],\n",
       "       [0.974, 0.924, 0.853],\n",
       "       [0.98 , 0.921, 0.858],\n",
       "       [0.98 , 0.917, 0.851],\n",
       "       [0.979, 0.935, 0.89 ],\n",
       "       [0.97 , 0.923, 0.863],\n",
       "       [0.971, 0.926, 0.857],\n",
       "       [0.97 , 0.928, 0.877],\n",
       "       [0.976, 0.935, 0.887],\n",
       "       [0.985, 0.94 , 0.879],\n",
       "       [0.972, 0.924, 0.871],\n",
       "       [0.972, 0.932, 0.868],\n",
       "       [0.977, 0.931, 0.883],\n",
       "       [0.97 , 0.912, 0.856],\n",
       "       [0.971, 0.923, 0.875],\n",
       "       [0.97 , 0.93 , 0.874],\n",
       "       [0.975, 0.928, 0.874],\n",
       "       [0.962, 0.901, 0.849],\n",
       "       [0.972, 0.923, 0.872],\n",
       "       [0.965, 0.92 , 0.863],\n",
       "       [0.979, 0.928, 0.875],\n",
       "       [0.976, 0.934, 0.881],\n",
       "       [0.973, 0.929, 0.879],\n",
       "       [0.977, 0.929, 0.875],\n",
       "       [0.973, 0.927, 0.875],\n",
       "       [0.973, 0.928, 0.869],\n",
       "       [0.968, 0.922, 0.862],\n",
       "       [0.976, 0.926, 0.868],\n",
       "       [0.978, 0.923, 0.875],\n",
       "       [0.972, 0.928, 0.874],\n",
       "       [0.977, 0.919, 0.872],\n",
       "       [0.972, 0.906, 0.847],\n",
       "       [0.97 , 0.925, 0.86 ],\n",
       "       [0.968, 0.923, 0.864],\n",
       "       [0.975, 0.928, 0.873],\n",
       "       [0.972, 0.937, 0.881],\n",
       "       [0.975, 0.919, 0.864],\n",
       "       [0.978, 0.921, 0.861],\n",
       "       [0.971, 0.922, 0.866],\n",
       "       [0.97 , 0.928, 0.87 ],\n",
       "       [0.973, 0.928, 0.872],\n",
       "       [0.976, 0.93 , 0.872],\n",
       "       [0.967, 0.919, 0.857],\n",
       "       [0.971, 0.927, 0.865],\n",
       "       [0.977, 0.932, 0.872],\n",
       "       [0.98 , 0.92 , 0.874],\n",
       "       [0.971, 0.92 , 0.868],\n",
       "       [0.979, 0.929, 0.874],\n",
       "       [0.978, 0.938, 0.881],\n",
       "       [0.973, 0.93 , 0.87 ],\n",
       "       [0.976, 0.938, 0.884],\n",
       "       [0.971, 0.926, 0.869],\n",
       "       [0.973, 0.919, 0.868],\n",
       "       [0.976, 0.937, 0.884],\n",
       "       [0.972, 0.922, 0.867],\n",
       "       [0.974, 0.927, 0.867],\n",
       "       [0.976, 0.929, 0.884],\n",
       "       [0.973, 0.929, 0.867],\n",
       "       [0.964, 0.912, 0.86 ],\n",
       "       [0.972, 0.911, 0.853],\n",
       "       [0.967, 0.914, 0.864],\n",
       "       [0.978, 0.93 , 0.886],\n",
       "       [0.979, 0.931, 0.87 ],\n",
       "       [0.984, 0.936, 0.888],\n",
       "       [0.967, 0.927, 0.872],\n",
       "       [0.97 , 0.925, 0.874],\n",
       "       [0.972, 0.929, 0.882],\n",
       "       [0.973, 0.919, 0.864],\n",
       "       [0.974, 0.925, 0.869],\n",
       "       [0.979, 0.912, 0.861],\n",
       "       [0.979, 0.933, 0.881],\n",
       "       [0.973, 0.937, 0.89 ],\n",
       "       [0.974, 0.932, 0.886],\n",
       "       [0.972, 0.924, 0.861],\n",
       "       [0.974, 0.93 , 0.886],\n",
       "       [0.967, 0.91 , 0.851],\n",
       "       [0.968, 0.906, 0.848],\n",
       "       [0.969, 0.932, 0.888],\n",
       "       [0.97 , 0.928, 0.873],\n",
       "       [0.981, 0.927, 0.877],\n",
       "       [0.967, 0.921, 0.867],\n",
       "       [0.973, 0.919, 0.855],\n",
       "       [0.979, 0.938, 0.877],\n",
       "       [0.976, 0.924, 0.88 ],\n",
       "       [0.983, 0.939, 0.873]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimations = 100\n",
    "\n",
    "MC = 1000\n",
    "\n",
    "zeros_init = np.zeros(shape = (n_estimations, 3))\n",
    "cov = np.zeros(shape = (n_estimations, 3))\n",
    "\n",
    "# Obtain 25 estimations of Type I coverage error for each distance and N, to calculate the mean of the estimations and the sample variance\n",
    "M = Wasserstein1D()\n",
    "\n",
    "for estimation in range(n_estimations):\n",
    "    yesno = np.zeros(3)\n",
    "    # Randomly select rows from the dataframe\n",
    "\n",
    "    new_ts, new_ys = gen_data(MC).values()\n",
    "\n",
    "    lns = coverage_df.sample(n=MC, replace = True)\n",
    "\n",
    "    i = 0\n",
    "    for _, ln in lns.iterrows():\n",
    "        # Generate one random point to test if it belongs to the prediction ball\n",
    "        new_t = new_ts[i]\n",
    "        #new_t = np.random.uniform(size = 1)\n",
    "        #Predict the new observation\n",
    "        new_pred = ln['forest'].predict(new_t.reshape(-1,1))\n",
    "        new_y = new_ys[i]\n",
    "        yesno = np.vstack((yesno, M.d(new_pred, new_y) <= ln['OOB_quantile']))\n",
    "        i += 1\n",
    "    cov[estimation, :] = yesno[1:,:].sum(axis=0) / MC\n",
    "    \n",
    "cov"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pballs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
